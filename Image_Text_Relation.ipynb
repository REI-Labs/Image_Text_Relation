{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d892cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "from PIL import Image\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fd28300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path you want to extract images from\n",
    "file = \"nke-20210531-(2)-Exhibits_IR.pdf\"\n",
    "# open the file\n",
    "pdf_file = fitz.open(file)\n",
    "\n",
    "# Output directory for the extracted images\n",
    "output_dir = \"extracted_images\"\n",
    "# Desired output image format\n",
    "output_format = \"png\"\n",
    "# Minimum width and height for extracted images\n",
    "min_width = 50\n",
    "min_height = 50\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# Iterate over PDF pages\n",
    "for page_index in range(len(pdf_file)):\n",
    "    # Get the page itself\n",
    "    page = pdf_file[page_index]\n",
    "    # Get image list\n",
    "    image_list = page.get_images(full=True)\n",
    "    # Print the number of images found on this page\n",
    "    # if image_list:\n",
    "        # print(f\"[+] Found a total of {len(image_list)} images in page {page_index}\")\n",
    "    # else:\n",
    "        # print(f\"[!] No images found on page {page_index}\")\n",
    "    # Iterate over the images on the page\n",
    "    for image_index, img in enumerate(image_list, start=1):\n",
    "        # Get the XREF of the image\n",
    "        xref = img[0]\n",
    "        # Extract the image bytes\n",
    "        base_image = pdf_file.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        # Get the image extension\n",
    "        image_ext = base_image[\"ext\"]\n",
    "        # Load it to PIL\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # Check if the image meets the minimum dimensions and save it\n",
    "        if image.width >= min_width and image.height >= min_height:\n",
    "            image.save(\n",
    "                open(os.path.join(output_dir, f\"image{page_index + 1}_{image_index}.{output_format}\"), \"wb\"),\n",
    "                format=output_format.upper())\n",
    "        else:\n",
    "            print(f\"[-] Skipping image {image_index} on page {page_index} due to its small size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "200433ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "raw_image = Image.open(\"extracted_images/image1_1.png\").convert('RGB')\n",
    "\n",
    "# conditional image captioning\n",
    "text = \"trademark of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "text = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "text2 = processor.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4dc32fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the nike logo'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.replace('trademark of','')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "00dd152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the nike logo'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = text.replace('trademark of','')\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0166b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "entities = [entity.text for entity in doc.ents]\n",
    " \n",
    "nouns = [token.lemma_ for token in doc if token.pos_ == \"NOUN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec35f404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nike']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9658f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "477170b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "doc = fitz.open('nke-20210531-(2)-Exhibits_IR.pdf')\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text+=page.get_text()\n",
    "text = ' '.join(text.split()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0e95d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = []\n",
    "\n",
    "for t in text.split('. '):\n",
    "    if keyword in t:\n",
    "        relevant.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c44ccbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8cd4bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = []\n",
    "for txt in relevant:\n",
    "    doc = nlp(txt)\n",
    "\n",
    "    chunks = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        out = {}\n",
    "        root = chunk.root\n",
    "        out[root.pos_] = root\n",
    "        for tok in chunk:\n",
    "            if tok != root:\n",
    "                out[tok.pos_] = tok\n",
    "        chunks.append(out)\n",
    "    \n",
    "    count = 0\n",
    "    for chunk in chunks:\n",
    "        if keyword in str(chunk):\n",
    "            count += len(chunk)\n",
    "    dependency.append(count)\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f806beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = pd.DataFrame(columns = [])\n",
    "chart['RelevantText'] = relevant\n",
    "chart['DependencyCount'] = dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0cb1eb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RelevantText</th>\n",
       "      <th>DependencyCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>the risks and uncertainties are detailed from ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>nike entities primarily purchase product in tw...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>revenues $ 44,538 $ 37,403 19 % 17 % $ 39,117 ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>air manufacturing innovation manufactures cush...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the company's reportable operating segments fo...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>nike brand wholesale equivalent revenues consi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>(1) (2),(3) 2021 form 10-k 30 table of content...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>(3) corporate revenues primarily consist of fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>higher revenues in north america contributed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>comparable store sales, which exclude digital ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          RelevantText  DependencyCount\n",
       "84   the risks and uncertainties are detailed from ...               21\n",
       "247  nike entities primarily purchase product in tw...               10\n",
       "145  revenues $ 44,538 $ 37,403 19 % 17 % $ 39,117 ...               10\n",
       "115  air manufacturing innovation manufactures cush...                9\n",
       "19   the company's reportable operating segments fo...                8\n",
       "..                                                 ...              ...\n",
       "141  nike brand wholesale equivalent revenues consi...                0\n",
       "143  (1) (2),(3) 2021 form 10-k 30 table of content...                0\n",
       "147  (3) corporate revenues primarily consist of fo...                0\n",
       "151  higher revenues in north america contributed a...                0\n",
       "158  comparable store sales, which exclude digital ...                0\n",
       "\n",
       "[316 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart.sort_values(by='DependencyCount',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bb122ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the company's reportable operating segments for the nike brand are: north america; europe, middle east & africa (emea); greater china; and asia pacific & latin america (apla), and include results for the nike and jordan brands\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart['RelevantText'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6d53506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67821137/spacy-how-to-get-all-words-that-describe-a-noun\n",
    "# https://www.thepythoncode.com/article/extract-pdf-images-in-python\n",
    "# https://neurondai.medium.com/how-to-extract-text-from-a-pdf-using-pymupdf-and-python-caa8487cf9d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
